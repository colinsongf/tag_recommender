{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Training (3 cores, memory bound)\n",
      "Preparation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import __builtin__\n",
      "\n",
      "import subprocess, shlex, os\n",
      "import time\n",
      "import pickle\n",
      "from collections import defaultdict, OrderedDict\n",
      "import itertools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "dv = client[:]\n",
      "print dv\n",
      "\n",
      "for eid in xrange(len(dv)):\n",
      "    client[eid]['eid'] = eid\n",
      "dv['num_eng'] = len(dv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<DirectView [0, 1, 2]>\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from __future__ import division\n",
      "import __builtin__\n",
      "import subprocess, shlex, os\n",
      "import time\n",
      "import numpy as np\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One-time Building"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build a tag <-> list of all indices of rows that contain the tag\n",
      "with open(\"../working/tags_lst.pickle\", 'r') as picklefile:\n",
      "    tags_lst = pickle.load(picklefile)\n",
      "\n",
      "tag_rows_index = defaultdict(list)\n",
      "for i, tags_line in enumerate(tags_lst):\n",
      "    for tag in tags_line.split():\n",
      "        tag_rows_index[tag].append(i)\n",
      "        \n",
      "# Sort tag_rows_index by occurrence\n",
      "sorted_items = sorted(tag_rows_index.iteritems(), key=lambda x: len(x[1]), reverse=True)\n",
      "tag_rows_index = OrderedDict(sorted_items)\n",
      "\n",
      "with open(\"../working/tag_rows_index.pickle\", 'w') as picklefile:\n",
      "    pickle.dump(tag_rows_index, picklefile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = 500\n",
      "with open(\"../working/M.pickle\", 'w') as picklefile:\n",
      "    pickle.dump(M, picklefile)\n",
      "\n",
      "dv['M'] = M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %%px\n",
      "# with open(\"../working/tag_rows_index.pickle\", 'r') as picklefile:\n",
      "#     tag_rows_index = pickle.load(picklefile)\n",
      "\n",
      "# tags_index = []\n",
      "# tag_iter = iter(tag_rows_index.iterkeys())\n",
      "\n",
      "# for iteration,tag in enumerate(tag_iter):\n",
      "#     if iteration == M: break\n",
      "#     if iteration % num_eng == eid:\n",
      "#         tags_index.append(tag)\n",
      "\n",
      "# with open(\"../working/tags_index_%d.pickle\" % eid, 'w') as picklefile:\n",
      "#     pickle.dump(tags_index, picklefile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "State-loading"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "\n",
      "with open(\"../working/N.pickle\", 'r') as picklefile:\n",
      "    N = pickle.load(picklefile)\n",
      "    \n",
      "with open(\"../working/bodies_lst.pickle\", 'r') as picklefile:\n",
      "    bodies_lst = pickle.load(picklefile)\n",
      "\n",
      "# with open(\"../working/titles_lst.pickle\", 'r') as picklefile:\n",
      "#     titles_lst = pickle.load(picklefile)\n",
      "\n",
      "with open(\"../working/tags_index_%d.pickle\" % eid, 'r') as picklefile:\n",
      "    tags_index = pickle.load(picklefile)\n",
      "    \n",
      "with open(\"../working/tag_rows_index.pickle\", 'r') as picklefile:\n",
      "    tag_rows_index = pickle.load(picklefile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "# Set up the sampling probabilities for each tag\n",
      "tag_counts = {k:len(v) for (k,v) in tag_rows_index.iteritems()}\n",
      "total_count = __builtin__.sum(tag_counts.itervalues())\n",
      "tag_probs = {k:v/total_count for (k,v) in tag_counts.iteritems()}\n",
      "labels, probs = tag_probs.keys(), tag_probs.values()\n",
      "del tag_probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "print \"len(tag_rows_index):\", len(tag_rows_index)\n",
      "print \"len(tags_index):\", len(tags_index)\n",
      "print \"len(tag_counts):\", len(tag_counts)\n",
      "print \"total_count:\", total_count\n",
      "print \"len(labels):\", len(labels)\n",
      "print \"len(probs):\", len(probs)\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] \n",
        "len(tag_rows_index): 8149\n",
        "len(tags_index): 167\n",
        "len(tag_counts): 8149\n",
        "total_count: 11266903\n",
        "len(labels): 8149\n",
        "len(probs): 8149\n",
        "\n",
        "[stdout:1] \n",
        "len(tag_rows_index): 8149\n",
        "len(tags_index): 167\n",
        "len(tag_counts): 8149\n",
        "total_count: 11266903\n",
        "len(labels): 8149\n",
        "len(probs): 8149\n",
        "\n",
        "[stdout:2] \n",
        "len(tag_rows_index): 8149\n",
        "len(tags_index): 166\n",
        "len(tag_counts): 8149\n",
        "total_count: 11266903\n",
        "len(labels): 8149\n",
        "len(probs): 8149\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "# Optimized O(N)-time, O(1)-auxiliary-space sample algorithm\n",
      "# http://stackoverflow.com/questions/6482889/get-random-sample-from-list-while-maintaining-ordering-of-items\n",
      "def inplace_n_choose(seq, k):\n",
      "    pick_count = 0\n",
      "    for i, val in enumerate(seq):\n",
      "        prob = (k - pick_count) / (len(seq) - i)\n",
      "        if np.random.random() < prob:\n",
      "            yield val\n",
      "            pick_count += 1\n",
      "\n",
      "def neg_indices_gen_helper(neg_tags, labels, tag_counts, tag_rows_index):\n",
      "    neg_indices_gen_lst = []\n",
      "    for label in labels:\n",
      "        k, right_lim = np.sum(neg_tags == label), tag_counts[label]\n",
      "        while k > right_lim:\n",
      "            neg_indices_gen_lst.append(inplace_n_choose(tag_rows_index[label], right_lim))\n",
      "            k -= right_lim\n",
      "        neg_indices_gen_lst.append(inplace_n_choose(tag_rows_index[label], k))\n",
      "        for neg_indices_gen in neg_indices_gen_lst:\n",
      "            for neg_index in neg_indices_gen:\n",
      "                yield neg_index\n",
      "\n",
      "def build_instances(doc_lst, indices):\n",
      "    instances = [] \n",
      "    for ind in indices:\n",
      "        instances.append(doc_lst[ind])\n",
      "    return instances"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Views:\n",
      "    tag_rows_index (sorted)\n",
      "    tags_index\n",
      "    tag_counts\n",
      "    labels\n",
      "    probs\n",
      "    bodies_lst"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Random stream passes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "\n",
      "init_train_cmd_template = \"vw --loss_function hinge -l 0.1 --l2 0.01 --l1 0.00005 -f ../working/vw/%s\"\n",
      "incr_train_cmd_template = \"vw --loss_function hinge -l 0.1 --l2 0.01 --l1 0.00005 -i ../working/vw/%s\" + \\\n",
      "\t\" -f ../working/vw/%s --feature_mask ../working/vw/%s\"\n",
      "debug_test_cmd_template = \"vw --quiet -t -p /dev/stdout -i ../working/vw/%s.model\"\n",
      "passes = 7\n",
      "\n",
      "for quitter, tag in enumerate(tags_index):\n",
      "    #if quitter < 245: continue\n",
      "    if quitter == 5: break\n",
      "    \n",
      "    curr_tag = tag\n",
      "    #ti = time.time()\n",
      "    ''' For each tag in the top M tags, choose Q = O/2 '+' examples, where O is occurence count '''\n",
      "    O = tag_counts[tag] # or, O = len(top_tag_rows_index[tag])\n",
      "    Q = O\n",
      "    ##Call `inplace_n_choose(tag_rows_index[tag], Q)` later\n",
      "    \n",
      "    ''' For each tag in the top M tags, choose P = 25*Q '-' examples '''\n",
      "    factor = 6\n",
      "    P = factor*Q\n",
      "    if Q+P > 0.75*N:\n",
      "        P = 0.75*N - Q\n",
      "    Q = int(Q)\n",
      "    P = int(P)\n",
      "    factor = P / Q\n",
      "    invfactor = 1.0 / factor\n",
      "    neg_tags = np.random.choice(labels, size=P, p=probs)\n",
      "    \n",
      "    ## If '+' tag, re-sample\n",
      "    uhohs = neg_tags == tag\n",
      "    while np.sum(uhohs) != 0:\n",
      "        neg_tags[uhohs] = np.random.choice(labels, size=np.sum(uhohs), p=probs)\n",
      "        uhohs = neg_tags == tag\n",
      "    ##Call `neg_indices_gen_helper(neg_tags, labels, tag_counts, tag_rows_index)` later\n",
      "    \n",
      "    ''' Build '+' and '-' instances '''\n",
      "    #pos_indices = inplace_n_choose(tag_rows_index[tag], Q)\n",
      "    pos_indices = tag_rows_index[tag]\n",
      "    neg_indices = neg_indices_gen_helper(neg_tags, labels, tag_counts, tag_rows_index)\n",
      "    pos_instances = build_instances(bodies_lst, pos_indices)\n",
      "    neg_instances = build_instances(bodies_lst, neg_indices)\n",
      "    #tj = time.time()\n",
      "    #print \"example sampling:\", tj - ti, \"seconds\"\n",
      "    \n",
      "    ''' Randomize and multiple passes '''\n",
      "    for epoch in xrange(passes):\n",
      "        #ta = time.time()\n",
      "    \t# Shuffle '+'s and '-'s, but keep track which is which\n",
      "        # If 1st epoch, create the model file\n",
      "        if epoch == 0:\n",
      "            cmd_str = init_train_cmd_template % (tag + '.feature')\n",
      "        elif epoch == 1:\n",
      "            cmd_str = incr_train_cmd_template % (tag + '.feature' , tag + '.model', tag + '.feature')\n",
      "        else:\n",
      "            cmd_str = incr_train_cmd_template % (tag + '.model', tag + '.model', tag + '.feature')\n",
      "    \tcmd = shlex.split(cmd_str)\n",
      "    \tvw = subprocess.Popen(cmd, stdin=subprocess.PIPE)\n",
      "        \n",
      "    \trandom_binaries = np.array([0]*(factor*Q) + [1]*Q, dtype=np.bool_)\n",
      "    \tnp.random.shuffle(random_binaries)\n",
      "    \tnp.random.shuffle(pos_instances)\n",
      "    \tnp.random.shuffle(neg_instances)\n",
      "    \tpos_iter, neg_iter = iter(pos_instances), iter(neg_instances)\n",
      "\n",
      "    \tfor b in random_binaries:\n",
      "    \t\tif b:\n",
      "    \t\t\tinstance = pos_iter.next()\n",
      "    \t\t\tvw.stdin.write('1 %.4f | ' % factor + instance + '\\n')\n",
      "    \t\telse:\n",
      "    \t\t\tinstance = neg_iter.next()\n",
      "    \t\t\tvw.stdin.write('-1 | ' + instance + '\\n')\n",
      "        \n",
      "        vw.stdin.flush()\n",
      "        vw.stdin.close()\n",
      "        vw.wait()\n",
      "        #tb = time.time()\n",
      "        #print \"Epoch %d:\" % (epoch+2), tb - ta, \"seconds\"\n",
      "    os.remove(\"../working/vw/%s\" % (tag + '.feature'))\n",
      "    \n",
      "    ''' Debug: print prediction performance along the way '''\n",
      "    pos_instances.extend(neg_instances)\n",
      "    debug_instances = pos_instances\n",
      "    del pos_instances, neg_instances\n",
      "    debug_str = \"| \" + \"\\n| \".join(debug_instances) + \"\\n\"\n",
      "    del debug_instances\n",
      "    cmd_str = debug_test_cmd_template % tag\n",
      "    cmd = shlex.split(cmd_str)\n",
      "    vw = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
      "    predictions = vw.communicate(input=debug_str)[0]\n",
      "    predictions = predictions.split('\\n')[:-1]\n",
      "    predictions = np.array(predictions, dtype=np.float32)\n",
      "    tps = predictions[:Q][predictions[:Q] > 0]\n",
      "    tp_avg = np.average(tps)\n",
      "    tp_std = np.std(tps)\n",
      "    fps = predictions[Q:Q+P][predictions[Q:Q+P] > 0]\n",
      "    fp_avg = np.average(fps)\n",
      "    fp_std = np.std(fps)\n",
      "    \n",
      "    # Iterative approximation to get the precision we want!\n",
      "    pred_thresh = tp_avg - 2*tp_std\n",
      "    tp = sum(tps > pred_thresh)\n",
      "    fp = sum(fps > pred_thresh)\n",
      "    raw_tp = tp\n",
      "    raw_fp = fp\n",
      "    p = tp / (tp + fp)\n",
      "    while p < 0.8: # target p=0.80\n",
      "        pred_thresh += tp_std / 8\n",
      "        tp = sum(tps > pred_thresh)\n",
      "        fp = sum(fps > pred_thresh)\n",
      "        p = tp / (tp + fp)\n",
      "    if p is np.nan:\n",
      "        pred_thresh = tp_avg - 2*tp_std\n",
      "        tp = np.sum(tps > pred_thresh)\n",
      "        fp = np.sum(fps > pred_thresh)\n",
      "        while fp / raw_fp > 0.2:\n",
      "            pred_thresh += tp_std / 8\n",
      "            tp = np.sum(tps > pred_thresh)\n",
      "            fp = np.sum(fps > pred_thresh)\n",
      "        p = tp / (tp + fp)\n",
      "    print \"average tp_pred_score:\", tp_avg\n",
      "    print \"average fp_pred_score:\", fp_avg\n",
      "    print \"std of tp_pred_score:\", tp_std\n",
      "    print \"std of fp_pred_score:\", fp_std\n",
      "    print \"pred_thresh:\", pred_thresh\n",
      "    print \"proportion tp included:\", tp / len(tps)\n",
      "    print \"proportion fp included:\", fp / len(fps)\n",
      "    fn = Q - tp\n",
      "    r = tp / (tp + fn)\n",
      "    f1 = 2*p*r/(p+r)\n",
      "    print \"%-4d, %-10s: tp is %-6d\\tfp is %-6d\\tp is %.4f\\tr is %.4f\" % (quitter, tag[:10], tp, fp, p, r)\n",
      "    print\n",
      "    \n",
      "    #t2 = time.time()\n",
      "    #print \"total vw training time:\", t2 - t0, \"seconds\"\n",
      "    #print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "print tag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] awk\n",
        "[stdout:1] xml-parsing\n",
        "[stdout:2] pdo\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Discriminative Testing (2 cores, CPU/thread bound)\n",
      "Preparations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reset -f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "dv = client[:]\n",
      "print dv\n",
      "\n",
      "num_eng = len(dv)\n",
      "for eid in xrange(num_eng):\n",
      "    client[eid]['eid'] = eid\n",
      "dv['num_eng'] = len(dv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<DirectView [0, 1]>\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from __future__ import division\n",
      "import subprocess, shlex, os\n",
      "import time\n",
      "import numpy as np\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"../working/M.pickle\", 'r') as picklefile:\n",
      "    M = pickle.load(picklefile)\n",
      "dv['M'] = M\n",
      "\n",
      "with open(\"../working/N.pickle\", 'r') as picklefile:\n",
      "    N = pickle.load(picklefile)\n",
      "dv['N'] = N\n",
      "N_test = N\n",
      "dv['N_test'] = N"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One-time building"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %%px\n",
      "# with open(\"../working/M.pickle\", 'r') as picklefile:\n",
      "#     M = pickle.load(picklefile)\n",
      "\n",
      "# with open(\"../working/tag_rows_index.pickle\", 'r') as picklefile:\n",
      "#     tag_rows_index = pickle.load(picklefile)\n",
      "\n",
      "# tags_index = []\n",
      "# tag_iter = iter(tag_rows_index.iterkeys())\n",
      "\n",
      "# for iteration,tag in enumerate(tag_iter):\n",
      "#     if iteration == M: break\n",
      "#     if iteration % num_eng == eid:\n",
      "#         tags_index.append(tag)\n",
      "\n",
      "# with open(\"../working/tags_index_test_%d.pickle\" % eid, 'w') as picklefile:\n",
      "#     pickle.dump(tags_index, picklefile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# with open(\"../working/bodies_lst.pickle\", 'r') as picklefile:\n",
      "#     bodies_lst = pickle.load(picklefile)\n",
      "\n",
      "# # with open(\"../working/titles_lst.pickle\", 'r') as picklefile:\n",
      "# #     titles_lst = pickle.load(picklefile)\n",
      "\n",
      "# # Convert bodies_lst to a vw-predicting-friendly format\n",
      "# Train_test_str = '| ' + '\\n| '.join(bodies_lst) + '\\n'\n",
      "# del bodies_lst\n",
      "\n",
      "# with open(\"../working/Train_test_str.pickle\", 'w') as picklefile:\n",
      "#     pickle.dump(Train_test_str, picklefile)\n",
      "# del Train_test_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../data/predictions.mmap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mm_preds = np.memmap(\"../data/predictions.mmap\", dtype=np.float32, mode='w+', shape=(M, N_test))\n",
      "del mm_preds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "State loading"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "\n",
      "with open(\"../working/Train_test_str.pickle\", 'r') as picklefile:\n",
      "    Train_test_str = pickle.load(picklefile)\n",
      "    \n",
      "with open(\"../working/tags_index_test_%d.pickle\" % eid, 'r') as picklefile:\n",
      "    tags_index = pickle.load(picklefile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv['start_off'] = 0\n",
      "for eid in xrange(num_eng):\n",
      "    for ec in xrange(eid):\n",
      "        client[eid]['start_off'] += len(client[ec-1]['tags_index'])\n",
      "\n",
      "print dv['start_off']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 250]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Stream Testing and mem-map storing. Using two cores takes around 2 hrs 40 min"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "t1 = time.time()\n",
      "cmd_template = \"vw --quiet -t -p /dev/stdout -i ../working/vw/%s.model\"# --cache_file ../working/vw/test%d.cache\"\n",
      "N_test = N\n",
      "mm_preds = np.memmap(\"../data/predictions.mmap\", dtype=np.float32, mode='r+', shape=(M, N_test))\n",
      "\n",
      "for quitter,tag in enumerate(tags_index):\n",
      "    #if quitter == 1: continue\n",
      "    #if quitter == 1: break\n",
      "    \n",
      "    #ta = time.time()\n",
      "    cmd_str = cmd_template % tag\n",
      "    cmd = shlex.split(cmd_str)\n",
      "    vw = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
      "    predictions = vw.communicate(input=Train_test_str)[0]\n",
      "    predictions = predictions.split('\\n')[:-1]\n",
      "    predictions = np.array(predictions, dtype=np.float32)\n",
      "    #tb = time.time()\n",
      "    #print \"non-cached-prediction time:\", tb - ta, \"seconds\"\n",
      "    \n",
      "    # do something with the predictions\n",
      "    #tc = time.time()\n",
      "    mm_preds[start_off+quitter, :] = predictions\n",
      "    #td = time.time()\n",
      "    #print \"storing predictions:\", td - tc, \"seconds\"\n",
      "\n",
      "del mm_preds\n",
      "t2 = time.time()\n",
      "print \"elapsed:\", t2 - t1, \"seconds\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] elapsed: 4358.48143578 seconds\n",
        "[stdout:1] elapsed: 4345.10890293 seconds\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Co-occurrence testing (4 cores)\n",
      "Preparations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reset -f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle, dill\n",
      "from collections import defaultdict\n",
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "lv = client.load_balanced_view()\n",
      "dv = client[:]\n",
      "print dv\n",
      "\n",
      "num_eng = len(dv)\n",
      "for eid in xrange(num_eng):\n",
      "    client[eid]['eid'] = eid\n",
      "dv['num_eng'] = len(dv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<DirectView [0, 1, 2, 3]>\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "from __future__ import division\n",
      "import time\n",
      "import numpy as np\n",
      "import pickle, dill\n",
      "import heapq\n",
      "import operator\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"../working/M.pickle\", 'r') as picklefile:\n",
      "    M = pickle.load(picklefile)\n",
      "dv['M'] = M\n",
      "\n",
      "with open(\"../working/N.pickle\", 'r') as picklefile:\n",
      "    N = pickle.load(picklefile)\n",
      "dv['N'] = N\n",
      "N_test = N\n",
      "dv['N_test'] = N"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One-time building"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"../working/tag_rows_index.pickle\", 'r') as picklefile:\n",
      "    tag_rows_index = pickle.load(picklefile)\n",
      "\n",
      "tag_counts = {k:len(v) for (k,v) in tag_rows_index.iteritems()}\n",
      "with open(\"../working/tag_counts.pickle\", 'r') as picklefile:\n",
      "    tag_counts = pickle.load(picklefile)\n",
      "del tag_counts\n",
      "\n",
      "tags_index = tag_rows_index.keys()[:M]\n",
      "del tag_rows_index\n",
      "\n",
      "# Note: tags_index_test is the second part. tags_index_test_%d refers to the first part\n",
      "with open(\"../working/tags_index_test.pickle\", 'w') as picklefile:\n",
      "    pickle.dump(tags_index, picklefile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a tags co-occurrence view.\n",
      "with open(\"../working/tags_lst.pickle\", 'r') as picklefile:\n",
      "    tags_lst = pickle.load(picklefile)\n",
      "    \n",
      "with open(\"../working/tags_index_test.pickle\", 'r') as picklefile:\n",
      "    tags_index = pickle.load(picklefile)\n",
      "\n",
      "top_tags_set = set(tags_index) # set for faster membership queries\n",
      "\n",
      "tags_co_occurrence = defaultdict(lambda : defaultdict(int)) # defaultdict(defaultdict(int)) intuitively\n",
      "\n",
      "for tags_str in tags_lst:\n",
      "    tags = tags_str.split()\n",
      "    for tag in tags:\n",
      "        if tag in top_tags_set:\n",
      "            for tag2 in tags:\n",
      "                if tag != tag2:\n",
      "                    tags_co_occurrence[tag][tag2] += 1\n",
      "\n",
      "with open(\"../working/tags_co_occurrence.pickle\", 'w') as picklefile:\n",
      "    pickle.dump(tags_co_occurrence, picklefile)\n",
      "\n",
      "del tags_lst, tags_index, tags_co_occurrence, top_tags_set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "State-loading"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "with open(\"../working/tags_co_occurrence.pickle\", 'r') as picklefile:\n",
      "    tags_co_occurrence = pickle.load(picklefile)\n",
      "\n",
      "with open(\"../working/tags_index_test.pickle\", 'r') as picklefile:\n",
      "    tags_index = pickle.load(picklefile)\n",
      "\n",
      "with open(\"../working/tag_counts.pickle\", 'r') as picklefile:\n",
      "    tag_counts = pickle.load(picklefile)\n",
      "\n",
      "with open(\"../working/tags_lst.pickle\", 'r') as picklefile:\n",
      "    tags_lst = pickle.load(picklefile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for eid in xrange(num_eng):\n",
      "    if eid == num_eng - 1: # if last engine\n",
      "        client[eid]['split_size'] = N_test - (num_eng-1)*(N_test // num_eng)\n",
      "    else:\n",
      "        client[eid]['split_size'] = N_test // num_eng\n",
      "\n",
      "dv['start_off'] = 0\n",
      "for eid in xrange(num_eng):\n",
      "    for ec in xrange(eid):\n",
      "        client[eid]['start_off'] += client[ec]['split_size']\n",
      "\n",
      "print dv['split_size']\n",
      "print dv['start_off']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1023848, 1023848, 1023848, 1023851]\n",
        "[0, 1023848, 2047696, 3071544]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "print \"N_test:\", N_test\n",
      "print \"start_off:\", start_off\n",
      "print \"split_size:\", split_size\n",
      "print \"start_off + split_size:\", start_off + split_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] \n",
        "N_test: 4095395\n",
        "start_off: 0\n",
        "split_size: 1023848\n",
        "start_off + split_size: 1023848\n",
        "[stdout:1] \n",
        "N_test: 4095395\n",
        "start_off: 1023848\n",
        "split_size: 1023848\n",
        "start_off + split_size: 2047696\n",
        "[stdout:2] \n",
        "N_test: 4095395\n",
        "start_off: 2047696\n",
        "split_size: 1023848\n",
        "start_off + split_size: 3071544\n",
        "[stdout:3] \n",
        "N_test: 4095395\n",
        "start_off: 3071544\n",
        "split_size: 1023851\n",
        "start_off + split_size: 4095395\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run through the co_occurrence matrix. If the co-occurrence rate for the top `M2` tags is higher than 0.42 (a little bit over the square root of 2), then automatically include that tag. This is done because the F-score can only go up above when above 0.42."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Actual co_occurrence predicting. Should take 20 minutes to finish."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "# Set the prediction thresholds\n",
      "pred_threshold = 0.100\n",
      "co_occurrence_threshold = 0.42 # baseline.. should only go up when configuring this number\n",
      "tp, fp, fn = 0, 0, 0\n",
      "mm_preds = np.memmap(\"../data/predictions.mmap\", dtype=np.float32, mode='r', shape=(M, N_test), order='F')\n",
      "\n",
      "ta = time.time()\n",
      "for i in xrange(start_off, start_off + split_size):\n",
      "    if i < start_off + 5000: continue\n",
      "    if i == start_off+5010: break\n",
      "    \n",
      "    mm_pred_row = mm_preds[:, i]\n",
      "    \n",
      "    pred_row = np.empty_like(mm_pred_row, dtype=mm_pred_row.dtype)\n",
      "    pred_row[:] = mm_pred_row[:]\n",
      "    # Select the top 5 tags that are over the threshold\n",
      "    # http://stackoverflow.com/questions/13070461/get-index-of-the-top-n-values-of-a-list-in-python\n",
      "    topn = 5\n",
      "    top5_top_preds = heapq.nlargest(topn, pred_row)\n",
      "    top5_top_indices = zip(*heapq.nlargest(topn, enumerate(pred_row), key=operator.itemgetter(1)))[0]\n",
      "    top5_top_tags = []\n",
      "    for x,ind in enumerate(top5_top_indices):\n",
      "        if top5_top_preds[x] > pred_threshold:\n",
      "            top5_top_tags.append(tags_index[ind])\n",
      "    \n",
      "    # If the selected tags number less than 5, include co-occurring tags above the 0.42 threshold\n",
      "    len_counter = len(top5_top_tags)\n",
      "    for s_tag in top5_top_tags:\n",
      "        co_tag_dict = tags_co_occurrence[s_tag]\n",
      "        for (co_tag, co_occurrence) in co_tag_dict.iteritems():\n",
      "            if len_counter < 5 and co_occurrence / tag_counts[s_tag] >= co_occurrence_threshold:\n",
      "                top5_top_tags.append(co_tag)\n",
      "                len_counter += 1\n",
      "            else:\n",
      "                break\n",
      "    # If there were no selected tags, then just predict the default top 5\n",
      "    if not top5_top_tags:\n",
      "        top5_top_tags = ['javascript',  'c#', 'python', 'php', 'java']\n",
      "    \n",
      "    # Get the true labels\n",
      "    true_tags = tags_lst[i].split()\n",
      "    true_inds = []\n",
      "    for ind, tag in enumerate(tags_index):\n",
      "        if tag in true_tags:\n",
      "            true_inds.append(ind)\n",
      "    print \"%d :\" % len(true_inds),\n",
      "    # Calculate the TP/FP/FN\n",
      "    tp_set = set(top5_top_tags) & set(true_tags)\n",
      "    fp_set = set(top5_top_tags) - set(true_tags)\n",
      "    fn_set = set(true_tags) - set(top5_top_tags)\n",
      "    tp += len(tp_set)\n",
      "    fp += len(fp_set)\n",
      "    fn += len(fn_set)\n",
      "    \n",
      "    a = zip(*heapq.nlargest(500, enumerate(pred_row), key=operator.itemgetter(1)))[0]\n",
      "    a = [b for b in a if b > 0]\n",
      "    for rank, ind in enumerate(a):\n",
      "        if ind in true_inds:\n",
      "            print rank,\n",
      "    print\n",
      "\n",
      "tb = time.time()\n",
      "#print \"total time elapsed:\", tb - ta, \"seconds\"\n",
      "\n",
      "#print tp, fp, fn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] \n",
        "3 : 50 246 353\n",
        "1 : 237\n",
        "3 : 215 218 465\n",
        "0 :\n",
        "3 : 30 411 489\n",
        "3 : 37 157 369\n",
        "2 : 106 329\n",
        "1 : 181\n",
        "0 :\n",
        "1 : 254\n",
        "[stdout:1] \n",
        "2 : 77 465\n",
        "3 : 92 363 419\n",
        "2 : 21\n",
        "4 : 111 212 364\n",
        "3 : 17 158 362\n",
        "0 :\n",
        "1 : 379\n",
        "1 : 160\n",
        "1 : 308\n",
        "3 : 135 175 418\n",
        "[stdout:2] \n",
        "1 : 114\n",
        "3 : 179 278\n",
        "2 : 103 362\n",
        "4 : 103 284 330 351\n",
        "3 : 113 347\n",
        "1 : 439\n",
        "2 : 72 384\n",
        "2 : 21 81\n",
        "4 : 35 88 109 388\n",
        "2 : 101 322\n",
        "[stdout:3] \n",
        "2 : 109 178\n",
        "2 : 207 462\n",
        "2 : 387 495\n",
        "2 : 45 126\n",
        "1 : 248\n",
        "1 : 330\n",
        "2 : 406\n",
        "2 : 113\n",
        "2 : 107 339\n",
        "2 : 255 290\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[stdout:0] 1023847\n",
        "[stdout:1] 2047695\n",
        "[stdout:2] 3071543\n",
        "[stdout:3] 4095394\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tp = sum([c['tp'] for c in dv.client])\n",
      "fp = sum([c['fp'] for c in dv.client])\n",
      "fn = sum([c['fn'] for c in dv.client])\n",
      "p = tp / (tp + fp)\n",
      "r = tp / (tp + fn)\n",
      "\n",
      "print \"tp:\", tp\n",
      "print \"fp:\", fp\n",
      "print \"fn:\", fn\n",
      "print\n",
      "print \"p:\", p\n",
      "print \"r:\", r\n",
      "print \"F1:\", 2*p*r/(p+r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tp: 99925\n",
        "fp: 19957196\n",
        "fn: 11166978\n",
        "\n",
        "p: 0.00498202109864\n",
        "r: 0.00886889680332\n",
        "F1: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.00638008705395\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}