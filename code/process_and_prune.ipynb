{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lib.iterators import *\n",
      "from lib.preprocessing import *\n",
      "from lib.pruning import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remove dupes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "remove_duplicate_rows(\"../data/Train.csv\", \"../data/Train_no_dupes.csv\", key=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NLTK Process"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split_csv(\"../data/Train_no_dupes.csv\", \"../data/Train_%d.csv\", 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# start 4 engines\n",
      "from IPython.parallel import Client\n",
      "client = Client()\n",
      "dv = client[:]\n",
      "for i, target in enumerate(dv.targets):\n",
      "    dv.client[target]['eid'] = i\n",
      "print dv['eid']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px process_csv(\"../data/Train_%d.csv\" % eid, \"../data/proc_Train_%d.csv\" % eid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prune by term-frequency"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loaded = True\n",
      "if loaded:\n",
      "    utitledict = Dictionary.load(\"../working/utitledict.pickle\")\n",
      "    ubodydict = Dictionary.load(\"../working/ubodydict.pickle\")\n",
      "    utagdict = Dictionary.load(\"../working/utagdict.pickle\")\n",
      "    print \"utitledict:\", utitledict\n",
      "    print \"ubodydict:\", ubodydict\n",
      "    print \"utagdict:\", utagdict\n",
      "    print \"loaded...\"\n",
      "else:\n",
      "    #utagdict = build_dictionary_from_splits(\"../data/proc_Train_%d.csv\",\n",
      "    #                                        -1, 4, \"../working/utagdict.pickle\")\n",
      "    utitledict, ubodydict, utagdict = build_dictionaries_from_splits(\"../data/proc_Train_%d.csv\",\n",
      "        4, save_pickle_tup=(\"../working/utitledict.pickle\", \"../working/ubodydict.pickle\", \"../working/utagdict.pickle\"))\n",
      "    print \"saved...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analyze_top_dfs(utitledict, utagdict)\n",
      "print\n",
      "analyze_top_dfs(ubodydict, utagdict, cutoff_factor=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"utagdict\"\n",
      "plot_dict_hist(utagdict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = utitledict.num_docs\n",
      "with open(\"../working/N.pickle\", 'w') as picklefile:\n",
      "    pickle.dump(N, picklefile)\n",
      "print \"number of documents before pruning:\", N"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titledict = filter_extremes_wrapper(utitledict, no_below=3, no_above=1.0, keep_n=None,\n",
      "                save_pickle=\"../working/titledict.pickle\")\n",
      "del utitledict\n",
      "\n",
      "with open(\"../working/N.pickle\", 'r') as picklefile:\n",
      "    N = pickle.load(picklefile)\n",
      "no_above = 2*327236/N\n",
      "bodydict = filter_extremes_wrapper(ubodydict, no_below=3, no_above=no_above, keep_n=None,\n",
      "               save_pickle=\"../working/bodydict.pickle\")\n",
      "del ubodydict\n",
      "\n",
      "tagdict = filter_extremes_wrapper(utagdict, no_below=100, no_above=1.0, keep_n=None,\n",
      "              save_pickle=\"../working/tagdict.pickle\")\n",
      "del utagdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "titledict = Dictionary.load(\"../working/titledict.pickle\")\n",
      "tagdict = Dictionary.load(\"../working/tagdict.pickle\")\n",
      "\n",
      "prune_csv_file2(\"../data/proc_Train_%d.csv\" % eid, \"../data/pruned_Train_%d.csv\" % eid,\n",
      "    (titledict, tagdict), (1, -1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extract_from_csvs(\"../data/pruned_Train_%d.csv\", \"../data/titleonly.txt\", 4, 1)\n",
      "extract_from_csvs(\"../data/pruned_Train_%d.csv\", \"../data/tagsonly.txt\", 4, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "num_eng = 2\n",
      "\n",
      "\n",
      "with open(\"../data/titleonly.txt\") as f_titles:\n",
      "    titles_lst = f_titles.read().split('\\n')[:-1]\n",
      "    tl = len(titles_lst)\n",
      "with open(\"../working/titles_lst.pickle\", 'wb') as picklefile:\n",
      "    pickle.dump(titles_lst, picklefile, -1)\n",
      "for eid in xrange(num_eng):\n",
      "    with open(\"../working/titles_lst_%d.pickle\" % eid, 'wb') as picklefile:\n",
      "        pickle.dump(titles_lst[eid*tl//2 : (eid+1)*tl//2], picklefile, -1)\n",
      "\n",
      "del titles_lst\n",
      "\n",
      "# with open(\"../data/bodyonly.txt\") as f_bodies:\n",
      "#     bodies_lst = f_bodies.read().split('\\n')[:-1]\n",
      "#     bl = len(bodies_lst)\n",
      "# with open(\"../working/bodies_lst.pickle\", 'wb') as picklefile:\n",
      "#     pickle.dump(bodies_lst, picklefile, -1)\n",
      "# for eid in xrange(num_eng):\n",
      "#     with open(\"../working/bodies_lst_%d.pickle\" % eid, 'wb') as picklefile:\n",
      "#         pickle.dump(bodies_lst[eid*bl//2 : (eid+1)*bl//2], picklefile, -1)\n",
      "\n",
      "# del bodies_lst\n",
      "\n",
      "with open(\"../data/tagsonly.txt\") as f_tags:\n",
      "    tags_lst = f_tags.read().split('\\n')[:-1]\n",
      "    tl = len(tags_lst)\n",
      "with open(\"../working/tags_lst.pickle\", 'wb') as picklefile:\n",
      "    pickle.dump(tags_lst, picklefile, -1)\n",
      "for eid in xrange(num_eng):\n",
      "    with open(\"../working/tags_lst_%d.pickle\" % eid, 'wb') as picklefile:\n",
      "        pickle.dump(tags_lst[eid*tl//2 : (eid+1)*tl//2], picklefile, -1)\n",
      "\n",
      "del tags_lst"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optional: Build recommender dictionaries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lib.recommender import build_dicts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}